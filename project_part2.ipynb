{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c64aee",
   "metadata": {},
   "source": [
    "# IRWA PROJECT PART 2\n",
    "Laia Tomàs Jané u198723\\\n",
    "Quim Ribas Martinez u198742 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caef35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import numpy as np\n",
    "import collections \n",
    "from collections import defaultdict\n",
    "from numpy import linalg as la\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1394c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed json from part 1\n",
    "products_df = pd.read_json(\"fashion_products_dataset_processed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0983a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy function from part1 for cleaning queries\n",
    "def build_terms(text):\n",
    "\n",
    "    #check that the text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    #keep only any word character or spaces (remove special characters and numbers) (includes removing punctuation marks)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text.lower()) \n",
    "\n",
    "    #tokenize text to a list of tokens\n",
    "    tokens = text.split()\n",
    "\n",
    "    #remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in tokens if word not in stop_words and len(word) > 2] #keep only words of length 3 minimum\n",
    "\n",
    "    #apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    text=[stemmer.stem(word) for word in text]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc80b4",
   "metadata": {},
   "source": [
    "### PART 1: INDEXING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23b7eb",
   "metadata": {},
   "source": [
    "#### Build inverted index. pregunta: full com a la practica o el d'exemple de lenunciat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447c502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index with just list of pids that contain the term\n",
    "def create_index2(df):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "\n",
    "    for _, line in df.iterrows():  # Remember, lines contain all documents from file\n",
    "        pid = line['pid']\n",
    "\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        \n",
    "        for term in terms:\n",
    "            if pid not in index[term]:  # avoid duplicates\n",
    "                index[term].append(pid)\n",
    "\n",
    "    return index, title_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffee389",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2, title_index2 = create_index2(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1aecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index with term as key and dict of pids as key and frequency of the term in the product as values. later used this one\n",
    "def create_index(df):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "    desc_index = {}\n",
    "\n",
    "    for _, line in df.iterrows():  # Remember, lines contain all documents from file\n",
    "        pid = line['pid']\n",
    "\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        desc = line['description']\n",
    "        desc_index[pid] = desc\n",
    "        \n",
    "        for term in terms:\n",
    "            try:\n",
    "                index[term][pid] += 1\n",
    "            except:\n",
    "                index[term][pid] = 1 #first entry\n",
    "\n",
    "    return index, title_index, desc_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2d0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index, title_index, desc_index = create_index(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e161fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first function to try to search queries, without any ranking\n",
    "def search(query, index):\n",
    "    \"\"\"\n",
    "    The output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersection of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)  # so that stemmed terms are matched in the index\n",
    "    products = None  # start with None to handle first term properly\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            term_products = set(index[term])  # documents containing this term\n",
    "\n",
    "            if products is None:\n",
    "                products = term_products  # initialize with first term's products\n",
    "            else:\n",
    "                products &= term_products  # intersection with the next term’s products\n",
    "\n",
    "        except:\n",
    "            # if a term isn't in the index, then no document contains *all* terms\n",
    "            return []\n",
    "\n",
    "    return list(products) if products else []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e00b57",
   "metadata": {},
   "source": [
    "#### test queries without ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "18955a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Sample of 5 results out of 1095 for the searched query (solid blue tshirt):\n",
      "\n",
      "product id= TSHFUHMWGNZTQMHP \n",
      "- product title: Solid Men Round Neck Blue T-Shirt \n",
      "- product description: Men's classic slim fit round neck t-shirt with half sleeves and logo patch. Pair this style with your choice of bottom for classy, casual summer look.\n",
      "\n",
      "product id= TSHFV9YU6KVGNTKF \n",
      "- product title: Solid Women Round Neck Dark Blue T-Shirt \n",
      "- product description: \n",
      "\n",
      "product id= TSHFJV3QA8GU7VC4 \n",
      "- product title: Solid Women Collared Neck Dark Blue T-Shirt \n",
      "- product description: Cheer on your favorite t-shirt in eye-popping colors and showcase your style. Each t-shirt is made of 100% cotton for a comfortable fit and breathable feel. Our brand has tapped into years of experience and used latest technology to give you a better experience. We strictly follow “no compromise on quality” This is perfect for every day wear and its clean-solid design allows you to wear for gym,jogging and etc. Still waiting?...get yours now before the stock ends.\n",
      "\n",
      "product id= TKPFNV3EVZGQYBNZ \n",
      "- product title: Solid Men Blue Track Pants \n",
      "- product description: ATHLET Trackpants Lower Jogger for men man gents boys - get fit and enjoy a sporty lifestyle with fully comfortable workout in gym trackpant lower for man which ensures greater flexibility with your every move activity. Team up this casual trackpant in blue and black color with any of your favorite t-shirts or sando/vest and create a sporty look. Made of 100% JACARD HOISERY fabric DRY-FIT technology to keep you dry all time while running gym sports cricket and any activity, this highly- comfortable lower is absorbent which provides you optimum comfort and keep you dry even when you are performing exercises on a hot sunny day or running on the road. Its stretchable fabric gives an ease of movement even when you are performing the complex exercises.\n",
      "\n",
      "product id= TSHFGBY8H7KF4ADY \n",
      "- product title: Solid Women Polo Neck Red, Blue, Light Green T-Shirt  (Pack of 3) \n",
      "- product description: EXPERIENCE THE AMAZING COMFORT OF A KEOTI POLO T-SHIRTS We know how it is as a busy student, father, or office worker. Some days getting dressed simply takes up too much time and you need something to throw on that looks simple and presentable. You don't want anything too fancy, just a cute and non-descript top that you can wear while you're on-the-go. This Polo T Shirt is exactly that! It's a great shirt for the everyday women to wear, anytime! This shirt is a necessary staple in everyday life. It is very versatile and can be worn in office environments, classrooms, and even during your errands or athletics activities. It's even machine washable, so all you need to do is toss it in the wash machine! THE KEOTI POLO T SHIRT IS MADE FOR FALL, SPRING, AND SUMMER! This great T-shirts was designed with you in mind! It has chambray seam finishes and a front button. It's even made 60% Cotton and 40% Polyester, so it is very lightweight and breathable. You can easily use this T-shirt as a great transitional piece for fall, spring, and summer! PRODUCT INFORMATION: Made of 60% Cotton and 40% Polyester Front Button Machine Washable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"solid blue tshirt\"\n",
    "products = search(query, index)\n",
    "top = 5\n",
    "\n",
    "print(\"======================\\nSample of {} results out of {} for the searched query ({}):\\n\".format(len(products[:top]), len(products), query))\n",
    "for p_id in products[:top]:\n",
    "    print(\"product id= {} \\n- product title: {} \\n- product description: {}\\n\".format(p_id, title_index[p_id], desc_index[p_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970ff73",
   "metadata": {},
   "source": [
    "#### ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2d110ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(products_df, num_products):\n",
    "    \"\"\"\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    num_documents -- total number of documents\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "\n",
    "    index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    tf = defaultdict(list)  #term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)  #document frequencies of terms in the corpus\n",
    "    title_index = defaultdict(str)\n",
    "    desc_index = defaultdict(str)\n",
    "    idf = defaultdict(float)\n",
    "\n",
    "    for _, line in products_df.iterrows():\n",
    "\n",
    "        pid = line['pid']\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        desc = line['description']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        desc_index[pid] = desc\n",
    "\n",
    "        current_product_terms = defaultdict(lambda: 0)\n",
    "        for term in terms:\n",
    "            current_product_terms[term] += 1\n",
    "            index[term][pid] += 1\n",
    "\n",
    "\n",
    "        # normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for freq in current_product_terms.values():\n",
    "            # posting will contain the list of positions for current term in current document.\n",
    "            # posting ==> [current_doc, [list of positions]]\n",
    "            # you can use it to infer the frequency of current term.\n",
    "            norm += freq ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        #calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, freq in current_product_terms.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(freq / norm, 4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1 # increment DF for current term\n",
    "\n",
    "\n",
    "    # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "    # Note: It is computed later after we know the df.\n",
    "    for term in df:\n",
    "        idf[term] = np.round(np.log(float(num_products / df[term])), 4)\n",
    "\n",
    "\n",
    "    return index, tf, df, idf, title_index, desc_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5cb260ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products = len(products_df)\n",
    "index, tf, df, idf, title_index, desc_index = create_index_tfidf(products_df, num_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7237d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Represent the query as a weighted tf-idf vector\n",
    "#Represent each product as a weighted tfidf vector\n",
    "#Compute the cosine similarity score for the\n",
    "#query vector and each product vector\n",
    "#Rank product with respect to the query by score\n",
    "#Return the top K (e.g., K = 10) to the user\n",
    "def rank_products(terms, pids, index, idf, tf, title_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    pids -- list of products, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked product\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the productVector corresponding to the query terms\n",
    "    # The remaining elements would become 0 when multiplied to the query_vector\n",
    "    products_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with products)\n",
    "        query_vector[termIndex] = query_terms_count[term] / query_norm * idf[term]\n",
    "\n",
    "        # Generate product_vectors for matching products\n",
    "        for pid_index, pid in enumerate(index[term].keys()):\n",
    "            # Example of pid_index, pid\n",
    "            # 0 JEAFNHERP6UHRQKH\n",
    "            # 1 JEAFNHERJGTGQ4GP\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the product JEAFNHERP6UHRQKH \n",
    "            if pid in pids:\n",
    "                products_vectors[pid][termIndex] = tf[term][pid_index] * idf[term]  \n",
    "\n",
    "    # Calculate the score of each product\n",
    "    # compute the cosine similarity between queyVector and each productVector:\n",
    "\n",
    "    products_scores = [[np.dot(curProdVec, query_vector), product] for product, curProdVec in products_vectors.items()]\n",
    "    products_scores.sort(reverse=True)\n",
    "    result_products = [x[1] for x in products_scores]\n",
    "    #print product titles instead if product id's\n",
    "    #result_products=[ title_index[x] for x in result_products ]\n",
    "    if len(result_products) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        # query = input()\n",
    "        # products = search_tf_idf(query, index)\n",
    "    #print ('\\n'.join(result_products), '\\n')\n",
    "    return result_products, products_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3478bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of products that contain any of the query terms.\n",
    "    So, we will get the list of products for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)  # so that stemmed terms are matched in the index\n",
    "    products = None  # start with None to handle first term properly\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            term_products = set(index[term])  # products containing this term\n",
    "\n",
    "            if products is None:\n",
    "                products = term_products  # initialize with first term's product\n",
    "            else:\n",
    "                products &= term_products  # intersection with the next term’s product\n",
    "\n",
    "        except:\n",
    "            # if a term isn't in the index, then no product contains ALL terms\n",
    "            return []\n",
    "    products = list(products)\n",
    "    ranked_products, product_scores = rank_products(query, products, index, idf, tf, title_index)\n",
    "    #print( ranked_products)\n",
    "    return ranked_products, product_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfd939",
   "metadata": {},
   "source": [
    "#### test queries with ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "216d920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k_query_results(query, index, k):\n",
    "    print(f\"Results for query: {query}\\n\")\n",
    "\n",
    "    ranked_products, scores = search_tf_idf(query, index)\n",
    "    print(\"======================\\nTop {} results out of {} for the searched query:\\n\".format(len(ranked_products[:k]), len(ranked_products)))\n",
    "    for p_id in ranked_products[:k]:\n",
    "        print(\"product_id= {} \\n- product_title: {} \\n- product_description: {}\\n\".format(p_id, title_index[p_id], desc_index[p_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb8c0b",
   "metadata": {},
   "source": [
    "##### Define 5 queries based on keywords ranked by term-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0eb4e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms by total TF:\n",
      "tshirt: 4585.3306\n",
      "women: 4043.7173\n",
      "men: 3955.4447\n",
      "neck: 3259.5684\n",
      "print: 2928.9821\n",
      "solid: 2494.3121\n",
      "round: 2343.7958\n",
      "shirt: 1827.0592\n",
      "fit: 1804.0305\n",
      "cotton: 1757.3377\n",
      "casual: 1556.9151\n",
      "pack: 1310.8927\n",
      "blue: 1245.1850\n",
      "sleev: 1123.0076\n",
      "comfort: 1108.3091\n"
     ]
    }
   ],
   "source": [
    "# rank by total TF\n",
    "tf_ranked = sorted(\n",
    "    ((term, sum(scores)) for term, scores in tf.items()),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Top terms by total TF:\")\n",
    "for term, score in tf_ranked[:15]:\n",
    "    print(f\"{term}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b5d40368",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"women blue casual tshirt\" \n",
    "query2 = \"cotton fit casual\"\n",
    "query3 = \"animal print tshirt\"\n",
    "query4 = \"round neck tshirt men\"\n",
    "query5 = \"solid shirt pack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0a1f9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: women blue casual tshirt\n",
      "\n",
      "======================\n",
      "Top 5 results out of 301 for the searched query:\n",
      "\n",
      "product_id= TSHEUJ4VFYTMZTXZ \n",
      "- product_title: Solid Women Round or Crew Blue T-Shirt \n",
      "- product_description: Axmann Light Blue Round Neck Casual Summer Wear Women T-shirt BY Axmann. Made with premium fabric for the most ultimate comfort. Range of vibrant colored casual t-shirts\n",
      "\n",
      "product_id= TSHFEY8VRGCMRSGG \n",
      "- product_title: Typography Women Round Neck Blue T-Shirt \n",
      "- product_description: Blue Chest print Kintted Cotton Casual T-shirts, has a round neck , Half Sleeve\n",
      "\n",
      "product_id= TSHEU7DTUYMHMGW6 \n",
      "- product_title: Striped Women Polo Neck Blue T-Shirt \n",
      "- product_description: Axmann Blue Striped Casual Wear Women Summer Polo T-shirt BY Axmann. Made with premium fabric for the most ultimate comfort. Range of vibrant colored casual t-shirts\n",
      "\n",
      "product_id= TSHEU7DSSQGESYNH \n",
      "- product_title: Printed Women Round Neck Blue T-Shirt \n",
      "- product_description: Axmann Blue Round Neck Casual Summer Wear Women T-shirt BY Axmann. Made with premium fabric for the most ultimate comfort. Range of vibrant colored casual t-shirt\n",
      "\n",
      "product_id= TSHEU7DTRZDFUEZB \n",
      "- product_title: Printed Women Round Neck Blue T-Shirt \n",
      "- product_description: Axmann Blue Round Neck Printed Casual Wear Women Summer T-shirt BY Axmann. Made with premium fabric for the most ultimate comfort. Range of vibrant colored casual t-shirt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_k_query_results(query1, index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4959facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: cotton fit casual\n",
      "\n",
      "======================\n",
      "Top 5 results out of 1072 for the searched query:\n",
      "\n",
      "product_id= SHTFVGSFSMEGVAYX \n",
      "- product_title: Men Slim Fit Solid Casual Shirt \n",
      "- product_description: Copper casual slim fit cotton shirt.\n",
      "\n",
      "product_id= SHTFVGSE7YBCVHYA \n",
      "- product_title: Women Slim Fit Solid Casual Shirt \n",
      "- product_description: Green casual slim fit shirt cut from cotton.\n",
      "\n",
      "product_id= SHTFS2GNV9SUCT6M \n",
      "- product_title: Women Slim Fit Checkered Casual Shirt \n",
      "- product_description: CANTABIL Women's Maroon 100% Cotton Slim Fit Casual Shirt\n",
      "\n",
      "product_id= SHTFS2GNPXXKXY2U \n",
      "- product_title: Women Slim Fit Checkered Casual Shirt \n",
      "- product_description: CANTABIL Women's Brown 100% Cotton Slim Fit Casual Shirt\n",
      "\n",
      "product_id= SHTFS2GNP3Z3CCHH \n",
      "- product_title: Men Slim Fit Striped Casual Shirt \n",
      "- product_description: CANTABIL Men's Navy 100% Cotton Slim Fit Casual Shirt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_k_query_results(query2, index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d6e8e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: animal print tshirt\n",
      "\n",
      "======================\n",
      "Top 2 results out of 2 for the searched query:\n",
      "\n",
      "product_id= TSHFNQW3FRSGET38 \n",
      "- product_title: Animal Print Women Round Neck Yellow T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFW2YBHHFP7TJW \n",
      "- product_title: Animal Print Men Round Neck Blue T-Shirt \n",
      "- product_description: When you want to look cool without compromising on comfort this T-shirt is what you need. you're going to make a great impression With an eye-catching design, this stylish t-shirt is ideal for everyday wear. 1/2 length sleeves and a round neck. Made from breathable cotton-rich fabric\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_k_query_results(query3, index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a0dd14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: round neck tshirt men\n",
      "\n",
      "======================\n",
      "Top 5 results out of 4097 for the searched query:\n",
      "\n",
      "product_id= TSHFUNN3QMCGSNCD \n",
      "- product_title: Printed Men Round Neck Pink T-Shirt \n",
      "- product_description: Men's Round Neck T-shirt\n",
      "\n",
      "product_id= TSHFUNN2WF5PB3NZ \n",
      "- product_title: Printed Men Round Neck White T-Shirt \n",
      "- product_description: Men's Round Neck T-shirt\n",
      "\n",
      "product_id= TSHFUNN2H8DUMJYQ \n",
      "- product_title: Printed Men Round Neck Blue T-Shirt \n",
      "- product_description: Men's Round Neck T-shirt\n",
      "\n",
      "product_id= TSHFVXGQ8Z5ZHCBS \n",
      "- product_title: Printed Men Round Neck Yellow T-Shirt \n",
      "- product_description: Men Mustard Round Neck Cotton T-shirt\n",
      "\n",
      "product_id= TSHFME2ERCGZHP6Y \n",
      "- product_title: Solid Men Round Neck Red T-Shirt \n",
      "- product_description: Steenbok Men's Short Sleeves Round Neck Tshirt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_k_query_results(query4, index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "47116711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: solid shirt pack\n",
      "\n",
      "======================\n",
      "Top 5 results out of 717 for the searched query:\n",
      "\n",
      "product_id= SHTFMBTYM2FKAKMN \n",
      "- product_title: Men Regular Fit Solid Formal Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= SHTFZNSJC8RZFF4W \n",
      "- product_title: Women Regular Fit Solid Slim Collar Casual Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= SHTFZNSJ8FXUECM5 \n",
      "- product_title: Men Regular Fit Solid Slim Collar Casual Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= SHTFT26KX5DEYK4H \n",
      "- product_title: Men Regular Fit Solid Spread Collar Casual Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= SHTFT26KMM39T2ZC \n",
      "- product_title: Women Regular Fit Solid Spread Collar Casual Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_k_query_results(query5, index, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59861a",
   "metadata": {},
   "source": [
    "## PART 2: EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "113c42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d41c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df['labels'].unique()\n",
    "# we already have a binary representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abffb41",
   "metadata": {},
   "source": [
    "### validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0fcccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(product_gt, y_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    product_gt: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]  \n",
    "    # Bonus point: How to improve the effitiency of this part?\n",
    "    #order = np.argsort(-y_score) #answer, or just get the idxs of top k positions, without sorting anything else\n",
    "\n",
    "    #doc_score = np.take(doc_score, order[:k])\n",
    "    product_gt = product_gt[order[:k]]\n",
    "    relevant = sum(product_gt == 1)\n",
    "    return float(relevant) / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d041fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(product_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1] \n",
    "    #same for efficiency\n",
    "    #order = np.argsort(-y_score) #answer\n",
    "     \n",
    "    product_score_at_k = product_score[order[:k]]\n",
    "    \n",
    "    relevant_at_k = np.sum(product_score_at_k == 1)\n",
    "    \n",
    "    total_relevant = np.sum(product_score == 1)\n",
    "    \n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return float(relevant_at_k) / total_relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bf5c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_at_k(product_gt, predicted_scores, k=10):\n",
    "    \n",
    "    sumatory = 0\n",
    "\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order[:k]]\n",
    "    relevant = sum(product_gt == 1)\n",
    "    number_to_iterate = min(k, len(order))\n",
    "\n",
    "\n",
    "    for i in range(1, number_to_iterate+1):\n",
    "        #sumatory += precision_at_k(product_gt, predicted_scores, i)*product_gt[i]\n",
    "        relevant_at_i = sum(product_gt[:i]==1)\n",
    "        sumatory += (relevant_at_i / i) * product_gt[i-1]\n",
    "\n",
    "    if relevant == 0:\n",
    "        return 0\n",
    "\n",
    "    return sumatory / relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2f8b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_at_k(product_gt, predicted_scores, k=10):\n",
    "    return 2 * (precision_at_k(product_gt, predicted_scores, k) * recall_at_k(product_gt, predicted_scores, k)) / (precision_at_k(product_gt, predicted_scores, k) + recall_at_k(product_gt, predicted_scores, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "03d34197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(queries_product_gt, queries_predicted_scores, k):\n",
    "    # queries is a dict with the query id as the key and the predicted scores for that query as the value\n",
    "    # queries_product_gt is also a dict with query id as the key and the ground truths for that query as the values\n",
    "    total = 0\n",
    "\n",
    "    for query, _ in queries_predicted_scores.items():\n",
    "        total += average_precision_at_k(queries_product_gt[query], queries_predicted_scores[query], k)\n",
    "\n",
    "    return total / len(queries_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "73679fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(product_gt, predicted_scores, k):\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order[:k]]\n",
    "\n",
    "    for i in range(len(order)):\n",
    "        if product_gt[i] == 1:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "def mean_reciprocal_rank(queries_product_gt, queries_predicted_scores, k):\n",
    "    \n",
    "    total = 0\n",
    "    for query, _ in queries_predicted_scores.items():\n",
    "        total += reciprocal_rank(queries_product_gt[query], queries_predicted_scores[query], k)\n",
    "\n",
    "    return total / len(queries_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "00be9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_p(product_gt, predicted_scores, p):\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order]\n",
    "    \n",
    "    DCG_p = 0\n",
    "    number_to_iterate = min(p, len(order))\n",
    "    for i in range (0,number_to_iterate):\n",
    "        DCG_p += (2**product_gt[i] - 1) / np.log2((i + 1) + 1)\n",
    "\n",
    "    return DCG_p\n",
    "\n",
    "def normalized_discounted_cumulative_gain(product_gt, predicted_scores, p):\n",
    "    DCG_p = dcg_at_p(product_gt, predicted_scores, p)\n",
    "\n",
    "    #Ideal DCG: sort by ground truth relevance descending\n",
    "    ideal_order = np.argsort(-product_gt)\n",
    "    ideal_gt = np.asarray(product_gt)[ideal_order][:p]\n",
    "    IDCG_p = dcg_at_p(ideal_gt, ideal_gt, p)\n",
    "\n",
    "    if IDCG_p == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return DCG_p / IDCG_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e7cb7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_at_k(queries_gt, queries_predicted_scores, k):\n",
    "\n",
    "    for query_id, query_gt in queries_gt.items():\n",
    "        products_gt = queries_gt[query_id]\n",
    "        predicted_scores = queries_predicted_scores[query_id]\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Results for query_id: \", query_id)\n",
    "        print(\"\\nPrecision@{}: {:.3g}\\n\".format(k, precision_at_k(products_gt, predicted_scores, k)))\n",
    "        print(\"Recall@{}: {:.3g}\\n\".format(k, recall_at_k(products_gt, predicted_scores, k)))\n",
    "        print(\"Average precision@{}: {:.3g}\\n\".format(k, average_precision_at_k(products_gt, predicted_scores, k)))\n",
    "        print(\"F1-Score@{}: {:.3g}\\n\".format(k, f1_score_at_k(products_gt, predicted_scores, k)))\n",
    "        print(\"Recall@{}: {:.3g}\\n\".format(k, recall_at_k(products_gt, predicted_scores, k)))\n",
    "        print(\"NDCG@{}: {:.3g}\".format(k, normalized_discounted_cumulative_gain(products_gt, predicted_scores, k)))\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"MAP@{}: {:.3g}\\n\".format(k, mean_average_precision(queries_gt, queries_predicted_scores, k)))\n",
    "    print(\"MRR@{}: {:.3g}\\n\".format(k, mean_reciprocal_rank(queries_gt, queries_predicted_scores, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c888958",
   "metadata": {},
   "source": [
    "### RESULTS FOR VALIDATION QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bd209a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"women full sleeve sweatshirt cotton\"\n",
    "query2 = \"men slim jeans blue\"\n",
    "\n",
    "result_products_q1, predicted_scores_q1 = search_tf_idf(query1, index)\n",
    "result_products_q2, predicted_scores_q2 = search_tf_idf(query2, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a2e2f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores_q1 = pd.DataFrame(predicted_scores_q1, columns=['predicted_score', 'pid'])\n",
    "predicted_scores_q2 = pd.DataFrame(predicted_scores_q2, columns=['predicted_score', 'pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "08516ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_q1 = validation_df[validation_df['query_id']==1][['pid', 'labels', 'query_id']]\n",
    "q1_scores_merged = validation_q1.merge(predicted_scores_q1, on='pid')\n",
    "\n",
    "validation_q2 = validation_df[validation_df['query_id']==2][['pid', 'labels', 'query_id']]\n",
    "q2_scores_merged = validation_q2.merge(predicted_scores_q2, on='pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd8514e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_gt = q1_scores_merged['labels'].values\n",
    "q1_predicted_scores = q1_scores_merged['predicted_score'].values\n",
    "\n",
    "q2_gt = q2_scores_merged['labels'].values\n",
    "q2_predicted_scores = q2_scores_merged['predicted_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "52707dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Results for query_id:  1\n",
      "\n",
      "Precision@10: 0.9\n",
      "\n",
      "Recall@10: 0.818\n",
      "\n",
      "Average precision@10: 1\n",
      "\n",
      "F1-Score@10: 0.857\n",
      "\n",
      "Recall@10: 0.818\n",
      "\n",
      "NDCG@10: 0.936\n",
      "--------------------------------------------------\n",
      "Results for query_id:  2\n",
      "\n",
      "Precision@10: 0.6\n",
      "\n",
      "Recall@10: 1\n",
      "\n",
      "Average precision@10: 0.948\n",
      "\n",
      "F1-Score@10: 0.75\n",
      "\n",
      "Recall@10: 1\n",
      "\n",
      "NDCG@10: 0.984\n",
      "--------------------------------------------------\n",
      "MAP@10: 0.974\n",
      "\n",
      "MRR@10: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dictionaries storing the query id and the ground truths and predicted scores\n",
    "queries_gt = {1: q1_gt, 2: q2_gt}\n",
    "queries_pred_scores = {1: q1_predicted_scores, 2: q2_predicted_scores}\n",
    "k = 10\n",
    "\n",
    "print_results_at_k(queries_gt, queries_pred_scores, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "32aacbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@10 from sklearn; 1.0\n",
      "Average precision@10: 1\n",
      "\n",
      "NDCG@10 from sklearn: 0.936\n",
      "NDCG@10: 0.936\n"
     ]
    }
   ],
   "source": [
    "# Check our functions with the available functions of sklearn library\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "\n",
    "k=10\n",
    "temp = q1_scores_merged.sort_values(\"predicted_score\", ascending=False).head(k)\n",
    "print(f\"Average Precision@{k} from sklearn;\", average_precision_score(np.array(temp[\"labels\"]), np.array(temp[\"predicted_score\"][:k])))\n",
    "print(\"Average precision@{}: {:.3g}\\n\".format(k, average_precision_at_k(q1_gt, q1_predicted_scores, k)))\n",
    "\n",
    "print(\"NDCG@{} from sklearn: {:.3g}\".format(k, ndcg_score([q1_gt], [q1_predicted_scores], k=k)))\n",
    "print(\"NDCG@{}: {:.3g}\".format(k, normalized_discounted_cumulative_gain(q1_gt, q1_predicted_scores, k)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
