{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c64aee",
   "metadata": {},
   "source": [
    "# IRWA PROJECT PART 2\n",
    "Laia Tomàs Jané u198723\\\n",
    "Quim Ribas Martinez u198742 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caef35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import numpy as np\n",
    "import collections \n",
    "from collections import defaultdict\n",
    "from numpy import linalg as la\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1394c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed json from part 1\n",
    "products_df = pd.read_json(\"fashion_products_dataset_processed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0983a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy function from part1 for cleaning queries\n",
    "def build_terms(text):\n",
    "\n",
    "    #check that the text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    #keep only any word character or spaces (remove special characters and numbers) (includes removing punctuation marks)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text.lower()) \n",
    "\n",
    "    #tokenize text to a list of tokens\n",
    "    tokens = text.split()\n",
    "\n",
    "    #remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in tokens if word not in stop_words and len(word) > 2] #keep only words of length 3 minimum\n",
    "\n",
    "    #apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    text=[stemmer.stem(word) for word in text]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc80b4",
   "metadata": {},
   "source": [
    "### PART 1: INDEXING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23b7eb",
   "metadata": {},
   "source": [
    "#### Build inverted index. pregunta: full com a la practica o el d'exemple de lenunciat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447c502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index with just list of pids that contain the term\n",
    "def create_index2(df):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "\n",
    "    for _, line in df.iterrows():  # Remember, lines contain all documents from file\n",
    "        pid = line['pid']\n",
    "\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        \n",
    "        for term in terms:\n",
    "            if pid not in index[term]:  # avoid duplicates\n",
    "                index[term].append(pid)\n",
    "\n",
    "    return index, title_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffee389",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2, title_index2 = create_index2(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1aecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index with term as key and dict of pids as key and frequency of the term in the product as values. later used this one\n",
    "def create_index(df):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "    desc_index = {}\n",
    "\n",
    "    for _, line in df.iterrows():  # Remember, lines contain all documents from file\n",
    "        pid = line['pid']\n",
    "\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        desc = line['description']\n",
    "        desc_index[pid] = desc\n",
    "        \n",
    "        for term in terms:\n",
    "            try:\n",
    "                index[term][pid] += 1\n",
    "            except:\n",
    "                index[term][pid] = 1 #first entry\n",
    "\n",
    "    return index, title_index, desc_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2d0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index, title_index, desc_index = create_index(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e161fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first function to try to search queries, without any ranking\n",
    "def search(query, index):\n",
    "    \"\"\"\n",
    "    The output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersection of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)  # so that stemmed terms are matched in the index\n",
    "    products = None  # start with None to handle first term properly\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            term_products = set(index[term])  # documents containing this term\n",
    "\n",
    "            if products is None:\n",
    "                products = term_products  # initialize with first term's products\n",
    "            else:\n",
    "                products &= term_products  # intersection with the next term’s products\n",
    "\n",
    "        except:\n",
    "            # if a term isn't in the index, then no document contains *all* terms\n",
    "            return []\n",
    "\n",
    "    return list(products) if products else []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e00b57",
   "metadata": {},
   "source": [
    "#### test queries without ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1351ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"solid blue\"\n",
    "len(search(query, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18955a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Sample of 5 results out of 1749 for the searched query (solid blue):\n",
      "\n",
      "product id= TSHF3V96629JYN5K \n",
      "- product title: Solid Men Round Neck Light Blue T-Shirt \n",
      "- product description: \n",
      "\n",
      "product id= TSHEN7UGEV9HGHSP \n",
      "- product title: Solid Men Round Neck Blue T-Shirt \n",
      "- product description: \n",
      "\n",
      "product id= TROFPSF86KDXBPUE \n",
      "- product title: Slim Fit Women Blue Pure Cotton Trousers \n",
      "- product description: The solid moon blue trousers offer crisp casual style. The pants feature a flat front, side and back pockets along with a waistband featuring belt loops.\n",
      "\n",
      "product id= TKPFWR7HGGWSKKD7 \n",
      "- product title: Solid Men Blue Track Pants \n",
      "- product description: \n",
      "\n",
      "product id= TKPF7BXYEDZAYEQQ \n",
      "- product title: Solid Women Blue Track Pants \n",
      "- product description: Mountain Colours Women's Trackpant. It is perfect addition to your wardrobe for comfortable wear. It has Elastic waist to make life comfortable. It has cotton fabric. It also has multiple pockets to make space for mobile phone, keys and wallet. Long wear sports wear hiking outing beach wear sleep wear casual home wear cool college wear movie outing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"solid blue\"\n",
    "products = search(query, index)\n",
    "top = 5\n",
    "\n",
    "print(\"======================\\nSample of {} results out of {} for the searched query ({}):\\n\".format(len(products[:top]), len(products), query))\n",
    "for p_id in products[:top]:\n",
    "    print(\"product id= {} \\n- product title: {} \\n- product description: {}\\n\".format(p_id, title_index[p_id], desc_index[p_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970ff73",
   "metadata": {},
   "source": [
    "#### ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d110ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(products_df, num_products):\n",
    "    \"\"\"\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    num_documents -- total number of documents\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "\n",
    "    index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    tf = defaultdict(list)  #term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)  #document frequencies of terms in the corpus\n",
    "    title_index = defaultdict(str)\n",
    "    desc_index = defaultdict(str)\n",
    "    idf = defaultdict(float)\n",
    "\n",
    "    for _, line in products_df.iterrows():\n",
    "\n",
    "        pid = line['pid']\n",
    "        terms = line['title_clean'] + line['description_clean']\n",
    "\n",
    "        title = line['title']\n",
    "        desc = line['description']\n",
    "        title_index[pid] = title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        desc_index[pid] = desc\n",
    "\n",
    "        current_product_terms = defaultdict(lambda: 0)\n",
    "        for term in terms:\n",
    "            current_product_terms[term] += 1\n",
    "            index[term][pid] += 1\n",
    "\n",
    "\n",
    "        # normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for freq in current_product_terms.values():\n",
    "            # posting will contain the list of positions for current term in current document.\n",
    "            # posting ==> [current_doc, [list of positions]]\n",
    "            # you can use it to infer the frequency of current term.\n",
    "            norm += freq ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        #calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, freq in current_product_terms.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(freq / norm, 4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1 # increment DF for current term\n",
    "\n",
    "\n",
    "    # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "    # Note: It is computed later after we know the df.\n",
    "    for term in df:\n",
    "        idf[term] = np.round(np.log(float(num_products / df[term])), 4)\n",
    "\n",
    "\n",
    "    return index, tf, df, idf, title_index, desc_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb260ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products = len(products_df)\n",
    "index, tf, df, idf, title_index, desc_index = create_index_tfidf(products_df, num_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7237d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Represent the query as a weighted tf-idf vector\n",
    "#Represent each product as a weighted tfidf vector\n",
    "#Compute the cosine similarity score for the\n",
    "#query vector and each product vector\n",
    "#Rank product with respect to the query by score\n",
    "#Return the top K (e.g., K = 10) to the user\n",
    "def rank_products(terms, pids, index, idf, tf, title_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    pids -- list of products, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked product\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the productVector corresponding to the query terms\n",
    "    # The remaining elements would become 0 when multiplied to the query_vector\n",
    "    products_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with products)\n",
    "        query_vector[termIndex] = query_terms_count[term] / query_norm * idf[term]\n",
    "\n",
    "        # Generate product_vectors for matching products\n",
    "        for pid_index, pid in enumerate(index[term].keys()):\n",
    "            # Example of pid_index, pid\n",
    "            # 0 JEAFNHERP6UHRQKH\n",
    "            # 1 JEAFNHERJGTGQ4GP\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the product JEAFNHERP6UHRQKH \n",
    "            if pid in pids:\n",
    "                products_vectors[pid][termIndex] = tf[term][pid_index] * idf[term]  \n",
    "\n",
    "    # Calculate the score of each product\n",
    "    # compute the cosine similarity between queyVector and each productVector:\n",
    "\n",
    "    products_scores = [[np.dot(curProdVec, query_vector), product] for product, curProdVec in products_vectors.items()]\n",
    "    products_scores.sort(reverse=True)\n",
    "    result_products = [x[1] for x in products_scores]\n",
    "    #print product titles instead if product id's\n",
    "    #result_products=[ title_index[x] for x in result_products ]\n",
    "    if len(result_products) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        # query = input()\n",
    "        # products = search_tf_idf(query, index)\n",
    "    #print ('\\n'.join(result_products), '\\n')\n",
    "    return result_products, products_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3478bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of products that contain any of the query terms.\n",
    "    So, we will get the list of products for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)  # so that stemmed terms are matched in the index\n",
    "    products = None  # start with None to handle first term properly\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            term_products = set(index[term])  # products containing this term\n",
    "\n",
    "            if products is None:\n",
    "                products = term_products  # initialize with first term's product\n",
    "            else:\n",
    "                products &= term_products  # intersection with the next term’s product\n",
    "\n",
    "        except:\n",
    "            # if a term isn't in the index, then no product contains ALL terms\n",
    "            return []\n",
    "    products = list(products)\n",
    "    ranked_products, product_scores = rank_products(query, products, index, idf, tf, title_index)\n",
    "    #print( ranked_products)\n",
    "    return ranked_products, product_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfd939",
   "metadata": {},
   "source": [
    "#### test queries with ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558e177",
   "metadata": {},
   "source": [
    "##### query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b94ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: solid blue):\n",
      "\n",
      "Results for query: solid blue\n",
      "\n",
      "======================\n",
      "Top 10 results out of 1749 for the searched query:\n",
      "\n",
      "product_id= TSHFZWRUTZK8HH3M \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Light Blue, Dark Blue, Black T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRUD9X6DG3M \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Light Blue, Dark Blue, White T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRU8FRFSVAJ \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Light Blue, Dark Blue, Grey T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRTZFZ4KE6K \n",
      "- product_title: Solid Men Round Neck Maroon, Blue, Light Blue, Dark Blue, Grey T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRT6BWSBQAQ \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Light Blue, Dark Blue, White T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRT2KTZJ7BK \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Light Blue, Dark Blue, Black T-Shirt  (Pack of 5) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFYFASUQVT8ZVE \n",
      "- product_title: Solid Men Polo Neck Dark Blue, Blue T-Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFYFASJWVNGVZG \n",
      "- product_title: Solid Women Polo Neck Blue, Light Blue T-Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFZWRTFNDDGH5K \n",
      "- product_title: Solid Women Round Neck Maroon, Blue, Dark Blue T-Shirt  (Pack of 3) \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFYFASGUU7JYVG \n",
      "- product_title: Solid Men Polo Neck Dark Blue, Light Blue T-Shirt  (Pack of 2) \n",
      "- product_description: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"solid blue\"\n",
    "print(f\"Insert your query (i.e.: {query}):\\n\")\n",
    "\n",
    "print(f\"Results for query: {query}\\n\")\n",
    "\n",
    "ranked_products, scores = search_tf_idf(query, index)\n",
    "top = 10\n",
    "\n",
    "print(\"======================\\nTop {} results out of {} for the searched query:\\n\".format(len(ranked_products[:top]), len(ranked_products)))\n",
    "for p_id in ranked_products[:top]:\n",
    "    print(\"product_id= {} \\n- product_title: {} \\n- product_description: {}\\n\".format(p_id, title_index[p_id], desc_index[p_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cd3fb",
   "metadata": {},
   "source": [
    "##### query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08193da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: dark blue tshirt\n",
      "\n",
      "======================\n",
      "Top 10 results out of 885 for the searched query:\n",
      "\n",
      "product_id= TSHFYUQKZVE6TWET \n",
      "- product_title: Color Block Women Round Neck Dark Blue, Dark Green T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFHB3MMVYKKPCY \n",
      "- product_title: Color Block Men Polo Neck Dark Blue, Dark Green T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFYURFAMGGKSPC \n",
      "- product_title: Color Block Women Round Neck Dark Green, White, Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFKNY6G5UMPYFE \n",
      "- product_title: Printed Women s Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFTN3VZ37H2HKP \n",
      "- product_title: Solid Women V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFTN3DC3VGHDCA \n",
      "- product_title: Solid Women V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFT59QDHQDRT6N \n",
      "- product_title: Solid Men V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFT59QCRYDTKUN \n",
      "- product_title: Solid Women V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFPY9HUWGNZPVG \n",
      "- product_title: Sporty Men V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n",
      "product_id= TSHFP9J5ECNUXHEJ \n",
      "- product_title: Printed Women V Neck Dark Blue T-Shirt \n",
      "- product_description: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"dark blue tshirt\"\n",
    "print(f\"Results for query: {query2}\\n\")\n",
    "\n",
    "ranked_products, scores = search_tf_idf(query2, index)\n",
    "top = 10\n",
    "\n",
    "print(\"======================\\nTop {} results out of {} for the searched query:\\n\".format(len(ranked_products[:top]), len(ranked_products)))\n",
    "for p_id in ranked_products[:top]:\n",
    "    print(\"product_id= {} \\n- product_title: {} \\n- product_description: {}\\n\".format(p_id, title_index[p_id], desc_index[p_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb8c0b",
   "metadata": {},
   "source": [
    "##### do other 3 queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59861a",
   "metadata": {},
   "source": [
    "## PART 2: EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abffb41",
   "metadata": {},
   "source": [
    "### validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "113c42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d41c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df['labels'].unique()\n",
    "# we already have a binary representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(product_gt, y_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    product_gt: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]  \n",
    "    # Bonus point: How to improve the effitiency of this part?\n",
    "    #order = np.argsort(-y_score) #answer, or just get the idxs of top k positions, without sorting anything else\n",
    "\n",
    "    #doc_score = np.take(doc_score, order[:k])\n",
    "    product_gt = product_gt[order[:k]]\n",
    "    relevant = sum(product_gt == 1)\n",
    "    return float(relevant) / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d041fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(product_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1] \n",
    "    #same for efficiency\n",
    "    #order = np.argsort(-y_score) #answer\n",
    "     \n",
    "    product_score_at_k = product_score[order[:k]]\n",
    "    \n",
    "    relevant_at_k = np.sum(product_score_at_k == 1)\n",
    "    \n",
    "    total_relevant = np.sum(product_score == 1)\n",
    "    \n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return float(relevant_at_k) / total_relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bf5c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_at_k(product_gt, predicted_scores, k=10):\n",
    "    \n",
    "    sumatory = 0\n",
    "\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order[:k]]\n",
    "    relevant = sum(product_gt == 1)\n",
    "\n",
    "    for i in range(1, k+1):\n",
    "        #sumatory += precision_at_k(product_gt, predicted_scores, i)*product_gt[i]\n",
    "        relevant_at_i = sum(product_gt[:i]==1)\n",
    "        sumatory += (relevant_at_i / i) * product_gt[i-1]\n",
    "\n",
    "    if relevant == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return sumatory / relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2f8b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_at_k(product_gt, predicted_scores, k=10):\n",
    "    return 2 * (precision_at_k(product_gt, predicted_scores, k) * recall_at_k(product_gt, predicted_scores, k)) / (precision_at_k(product_gt, predicted_scores, k) + recall_at_k(product_gt, predicted_scores, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03d34197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(queries_predicted_scores, queries_product_gt, k):\n",
    "    # queries is a dict with the query id as the key and the predicted scores for that query as the value\n",
    "    # queries_product_gt is also a dict with query id as the key and the ground truths for that query as the values\n",
    "    total = 0\n",
    "\n",
    "    for query, _ in queries_predicted_scores.items():\n",
    "        total += average_precision_at_k(queries_product_gt[query], queries_predicted_scores[query], k)\n",
    "\n",
    "    return total / len(queries_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73679fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(product_gt, predicted_scores):\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order]\n",
    "\n",
    "    for i in range(len(order)):\n",
    "        if product_gt[i] == 1:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "def mean_reciprocal_rank(queries_predicted_scores, queries_product_gt):\n",
    "    \n",
    "    total = 0\n",
    "    for query, _ in queries_predicted_scores.items():\n",
    "        total += reciprocal_rank(queries_product_gt[query], queries_predicted_scores[query])\n",
    "\n",
    "    return total / len(queries_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_p(product_gt, predicted_scores, p):\n",
    "    order = np.argsort(predicted_scores)[::-1]  \n",
    "    product_gt = product_gt[order]\n",
    "\n",
    "    DCG_p = product_gt[0]\n",
    "\n",
    "    for i in range (1,p):\n",
    "        DCG_p += product_gt[i] / np.log2(i+1)\n",
    "\n",
    "    return DCG_p\n",
    "\n",
    "def normalized_discounted_cumulative_gain(product_gt, predicted_scores, p):\n",
    "    DCG_p = dcg_at_p(product_gt, predicted_scores, p)\n",
    "\n",
    "    # Ideal DCG: sort by ground truth relevance descending\n",
    "    ideal_order = np.argsort(-product_gt)\n",
    "    ideal_gt = np.asarray(product_gt)[ideal_order][:p]\n",
    "    IDCG_p = dcg_at_p(ideal_gt, ideal_gt, p)\n",
    "\n",
    "    if IDCG_p == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return DCG_p / IDCG_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c888958",
   "metadata": {},
   "source": [
    "### VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bd209a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"women full sleeve sweatshirt cotton\"\n",
    "query2 = \"men slim jeans blue\"\n",
    "\n",
    "result_products_q1, predicted_scores_q1 = search_tf_idf(query1, index)\n",
    "result_products_q2, predicted_scores_q2 = search_tf_idf(query2, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2e2f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores_q1 = pd.DataFrame(predicted_scores_q1, columns=['predicted_score', 'pid'])\n",
    "predicted_scores_q2 = pd.DataFrame(predicted_scores_q2, columns=['predicted_score', 'pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #just retrieve the scores\n",
    "# predicted_scores_q1 = [x[0] for x in predicted_scores_q1]\n",
    "# predicted_scores_q2 = [x[0] for x in predicted_scores_q2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2879d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_gt_q1 = validation_df[validation_df['query_id']==1]['labels']\n",
    "# validation_gt_q1 = validation_gt_q1.to_list()\n",
    "\n",
    "# validation_gt_q2 = validation_df[validation_df['query_id']==2]['labels']\n",
    "# validation_gt_q2 = validation_gt_q2.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "08516ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_q1 = validation_df[validation_df['query_id']==1][['pid', 'labels']]\n",
    "q1_scores_merged = validation_q1.merge(predicted_scores_q1, on='pid')\n",
    "\n",
    "validation_q2 = validation_df[validation_df['query_id']==2][['pid', 'labels']]\n",
    "q2_scores_merged = validation_q2.merge(predicted_scores_q2, on='pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd8514e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_gt = q1_scores_merged['labels'].values\n",
    "q1_predicted_scores = q1_scores_merged['predicted_score'].values\n",
    "\n",
    "q2_gt = q2_scores_merged['labels'].values\n",
    "q2_predicted_scores = q2_scores_merged['predicted_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "207e7cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(q1_gt, q1_predicted_scores, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2f33bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(q1_gt, q1_predicted_scores, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "db4045b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(q2_gt, q2_predicted_scores, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "08625d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(q2_gt, q2_predicted_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cb29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
